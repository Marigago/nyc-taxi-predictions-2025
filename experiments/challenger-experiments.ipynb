{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e3ad8fb",
   "metadata": {},
   "source": [
    "## Cambiar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c0a50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/21 15:40:09 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/10/21 15:40:09 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# === MLflow ===\n",
    "TRACKING_URI = \"sqlite:///mlflow.db\"\n",
    "EXPERIMENT_NAME = \"nyc-taxi-challenger\"\n",
    "REGISTERED_MODEL_NAME = \"nyc-taxi-model\"   # ya existe en tu registry\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "client = MlflowClient(tracking_uri=TRACKING_URI)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13dabe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    df[\"lpep_dropoff_datetime\"] = pd.to_datetime(df[\"lpep_dropoff_datetime\"])\n",
    "    df[\"lpep_pickup_datetime\"] = pd.to_datetime(df[\"lpep_pickup_datetime\"])\n",
    "    df[\"duration\"] = (df.lpep_dropoff_datetime - df.lpep_pickup_datetime).dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    df[[\"PULocationID\", \"DOLocationID\"]] = df[[\"PULocationID\", \"DOLocationID\"]].astype(str)\n",
    "    return df\n",
    "\n",
    "def build_features(df, dv=None, fit_dv=False):\n",
    "    df = df.copy()\n",
    "    df[\"PU_DO\"] = df[\"PULocationID\"] + \"_\" + df[\"DOLocationID\"]\n",
    "    categorical = [\"PU_DO\"]\n",
    "    numerical = [\"trip_distance\"]\n",
    "    dicts = df[categorical + numerical].to_dict(orient=\"records\")\n",
    "\n",
    "    if fit_dv:\n",
    "        dv = DictVectorizer(sparse=True)\n",
    "        X = dv.fit_transform(dicts)\n",
    "    else:\n",
    "        X = dv.transform(dicts)\n",
    "\n",
    "    y = df[\"duration\"].values\n",
    "    return X, y, dv\n",
    "\n",
    "# paths de entrenamiento/validación (mismo split que tu ejemplo)\n",
    "train_path = \"../data/green_tripdata_2025-01.parquet\"\n",
    "val_path   = \"../data/green_tripdata_2025-02.parquet\"\n",
    "\n",
    "df_train = read_dataframe(train_path)\n",
    "df_val   = read_dataframe(val_path)\n",
    "\n",
    "# DictVectorizer (compartido por todos los experimentos de este notebook)\n",
    "X_train, y_train, dv = build_features(df_train, dv=None, fit_dv=True)\n",
    "X_val,   y_val,   _  = build_features(df_val, dv=dv, fit_dv=False)\n",
    "\n",
    "# Guarda el preprocesador para adjuntarlo como artifact en cada run\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "with open(\"models/preprocessor.b\", \"wb\") as f:\n",
    "    pickle.dump(dv, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af3b7def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def densify_with_sample(X, y, max_rows=120_000):\n",
    "    n = X.shape[0]\n",
    "    if n > max_rows:\n",
    "        idx = np.random.choice(n, size=max_rows, replace=False)\n",
    "        X_sub = X[idx]\n",
    "        y_sub = y[idx]\n",
    "    else:\n",
    "        X_sub = X\n",
    "        y_sub = y\n",
    "    X_dense = X_sub.toarray().astype(\"float32\")  # reducir uso de memoria\n",
    "    return X_dense, y_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c577449d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 15:59:10,167] A new study created in memory with name: no-name-dea92eca-450a-47f1-8bc2-a297cdf622ba\n",
      "2025/10/21 16:05:57 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/21 16:05:59 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/21 16:05:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-10-21 16:05:59,817] Trial 0 finished with value: 5.477489002306669 and parameters: {'n_estimators': 196, 'learning_rate': 0.2964579088358797, 'max_depth': 5}. Best is trial 0 with value: 5.477489002306669.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.477489002306669,\n",
       " {'n_estimators': 196, 'learning_rate': 0.2964579088358797, 'max_depth': 5})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# === PRECOMPUTE: un solo muestreo pequeño y densificación ===\n",
    "Xtr_dense_small, ytr_small = densify_with_sample(X_train, y_train, max_rows=30_000)\n",
    "Xva_dense_small, yva_small = densify_with_sample(X_val,   y_val,   max_rows=15_000)\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import time\n",
    "\n",
    "PARENT_NAME_GB = \"GB_parent_fast\"\n",
    "\n",
    "def gb_objective_fast(trial):\n",
    "    # Espacio reducido (más rápido)\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 60, 220),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.03, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 6),\n",
    "        \"subsample\": 0.8,  # fijo para acelerar\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True, run_name=f\"GB_child_fast_{trial.number}\"):\n",
    "        model = GradientBoostingRegressor(**params)\n",
    "        tic = time.time()\n",
    "        model.fit(Xtr_dense_small, ytr_small)\n",
    "        fit_time = time.time() - tic\n",
    "\n",
    "        y_pred = model.predict(Xva_dense_small)\n",
    "        rmse = root_mean_squared_error(yva_small, y_pred)\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"fit_time_s\", fit_time)\n",
    "        mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    return rmse\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "with mlflow.start_run(run_name=PARENT_NAME_GB):\n",
    "    mlflow.set_tags({\"role\": \"parent\", \"model_family\": \"GradientBoosting\", \"mode\": \"fast\"})\n",
    "    # Menos trials + límite de tiempo\n",
    "    study.optimize(gb_objective_fast, n_trials=8, timeout=300, show_progress_bar=False)\n",
    "\n",
    "best_gb_rmse = study.best_value\n",
    "best_gb_params = study.best_params\n",
    "best_gb_rmse, best_gb_params\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af64a1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 17:21:45,886] A new study created in memory with name: no-name-b32be769-c253-49c7-82b9-33a327d0f034\n",
      "2025/10/21 17:21:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/21 17:21:49 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/21 17:21:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-10-21 17:21:49,411] Trial 0 finished with value: 8.909299537488362 and parameters: {'n_estimators': 173, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 0 with value: 8.909299537488362.\n",
      "2025/10/21 17:21:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/21 17:21:54 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/21 17:21:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-10-21 17:21:54,217] Trial 1 finished with value: 8.724166369406431 and parameters: {'n_estimators': 148, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 1 with value: 8.724166369406431.\n",
      "2025/10/21 17:22:03 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/21 17:22:05 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/21 17:22:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-10-21 17:22:05,931] Trial 2 finished with value: 8.366976511121173 and parameters: {'n_estimators': 269, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 2 with value: 8.366976511121173.\n",
      "2025/10/21 17:22:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/21 17:22:08 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/21 17:22:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-10-21 17:22:08,804] Trial 3 finished with value: 8.973510461656403 and parameters: {'n_estimators': 117, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 2 with value: 8.366976511121173.\n",
      "2025/10/21 17:22:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/21 17:22:17 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/21 17:22:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-10-21 17:22:17,909] Trial 4 finished with value: 8.983499765097811 and parameters: {'n_estimators': 138, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 2 with value: 8.366976511121173.\n",
      "2025/10/21 17:22:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/21 17:22:25 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/21 17:22:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-10-21 17:22:25,694] Trial 5 finished with value: 8.204351711306584 and parameters: {'n_estimators': 111, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 5 with value: 8.204351711306584.\n",
      "2025/10/21 17:22:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/21 17:22:28 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/21 17:22:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-10-21 17:22:28,797] Trial 6 finished with value: 8.881837353227574 and parameters: {'n_estimators': 219, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 5 with value: 8.204351711306584.\n",
      "2025/10/21 17:22:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/21 17:22:31 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/21 17:22:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "[I 2025-10-21 17:22:31,365] Trial 7 finished with value: 8.941100029181298 and parameters: {'n_estimators': 249, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 5 with value: 8.204351711306584.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8.204351711306584,\n",
       " {'n_estimators': 111,\n",
       "  'max_depth': 15,\n",
       "  'min_samples_split': 6,\n",
       "  'min_samples_leaf': 5,\n",
       "  'max_features': 'sqrt'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# === PRECOMPUTE: un solo muestreo pequeño y densificación (rápido) ===\n",
    "Xtr_dense_small, ytr_small = densify_with_sample(X_train, y_train, max_rows=30_000)\n",
    "Xva_dense_small, yva_small = densify_with_sample(X_val,   y_val,   max_rows=15_000)\n",
    "\n",
    "import optuna\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "PARENT_NAME_RF = \"RF_parent_fast\"\n",
    "\n",
    "def rf_objective_fast(trial):\n",
    "    # Espacio reducido → mucho más rápido\n",
    "    params = {\n",
    "        \"n_estimators\":      trial.suggest_int(\"n_estimators\", 100, 320),   # menos árboles\n",
    "        \"max_depth\":         trial.suggest_int(\"max_depth\", 4, 16),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 8),\n",
    "        \"min_samples_leaf\":  trial.suggest_int(\"min_samples_leaf\", 1, 6),\n",
    "        \"max_features\":      trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "        \"bootstrap\":         True,   # fijo\n",
    "        \"n_jobs\":            -1,\n",
    "        \"random_state\":      RANDOM_STATE,\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True, run_name=f\"RF_child_fast_{trial.number}\"):\n",
    "        model = RandomForestRegressor(**params)\n",
    "        tic = time.time()\n",
    "        model.fit(Xtr_dense_small, ytr_small)\n",
    "        fit_time = time.time() - tic\n",
    "\n",
    "        y_pred = model.predict(Xva_dense_small)\n",
    "        rmse = root_mean_squared_error(yva_small, y_pred)\n",
    "\n",
    "        # logging MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"fit_time_s\", fit_time)\n",
    "        mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    return rmse\n",
    "\n",
    "study_rf = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "with mlflow.start_run(run_name=PARENT_NAME_RF):\n",
    "    mlflow.set_tags({\"role\": \"parent\", \"model_family\": \"RandomForest\", \"mode\": \"fast\"})\n",
    "    # Pocos trials + límite de tiempo (5 min). Sube/baja según tu máquina.\n",
    "    study_rf.optimize(rf_objective_fast, n_trials=8, timeout=300, show_progress_bar=False)\n",
    "\n",
    "best_rf_rmse   = study_rf.best_value\n",
    "best_rf_params = study_rf.best_params\n",
    "best_rf_rmse, best_rf_params\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f8b6879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fa642cf4081e45e897fea88fa5219321', None, 5.477489002306669)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Selección robusta del mejor run por RMSE ===\n",
    "exp = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if exp is None:\n",
    "    raise ValueError(f\"Experimento '{EXPERIMENT_NAME}' no existe. Asegúrate de haber hecho mlflow.set_experiment('{EXPERIMENT_NAME}') antes de loguear.\")\n",
    "\n",
    "# Trae todo y luego filtramos en pandas (evita problemas con NULL en tags)\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_ids=[exp.experiment_id],\n",
    "    order_by=[\"metrics.rmse ASC\", \"start_time DESC\"]\n",
    ")\n",
    "\n",
    "if runs.empty:\n",
    "    raise ValueError(\n",
    "        \"No se encontraron runs en este experimento. \"\n",
    "        \"Revisa que tus entrenamientos hayan corrido en este EXPERIMENT_NAME.\"\n",
    "    )\n",
    "\n",
    "# Quita explícitamente los parents (role == 'parent') y los runs sin rmse\n",
    "mask_not_parent = runs[\"tags.role\"].fillna(\"\").ne(\"parent\")\n",
    "mask_has_rmse   = runs[\"metrics.rmse\"].notna()\n",
    "child_runs = runs[mask_not_parent & mask_has_rmse].copy()\n",
    "\n",
    "if child_runs.empty:\n",
    "    # Diagnóstico rápido\n",
    "    print(\"Diagnóstico:\")\n",
    "    print(\"- Cantidad total de runs:\", len(runs))\n",
    "    print(\"- Cantidad con tag role='parent':\", (runs['tags.role'] == 'parent').sum())\n",
    "    print(\"- ¿Hay columna 'metrics.rmse'? ->\", 'metrics.rmse' in runs.columns)\n",
    "    print(\"- Cantidad con rmse no nulo:\", runs['metrics.rmse'].notna().sum())\n",
    "    raise ValueError(\n",
    "        \"No hay child runs con métrica 'rmse'. \"\n",
    "        \"Asegúrate de hacer mlflow.log_metric('rmse', ...) dentro de cada child run \"\n",
    "        \"y que no fallen/timeout antes de loguear.\"\n",
    "    )\n",
    "\n",
    "# Ordena y toma el mejor\n",
    "child_runs = child_runs.sort_values(by=[\"metrics.rmse\", \"start_time\"], ascending=[True, False])\n",
    "best_run   = child_runs.iloc[0]\n",
    "\n",
    "best_run_id = best_run.run_id\n",
    "best_rmse   = float(best_run[\"metrics.rmse\"])\n",
    "best_model_family = best_run.get(\"tags.model_family\", \"desconocido\")\n",
    "\n",
    "best_run_id, best_model_family, best_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1dff0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/21 19:47:38 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/10/21 19:47:38 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Registered model 'nyc-taxi-model' already exists. Creating a new version of this model...\n",
      "2025/10/21 19:47:38 WARNING mlflow.tracking._model_registry.fluent: Run with id fa642cf4081e45e897fea88fa5219321 has no artifacts at artifact path 'model', registering model based on models:/m-d901fba5daea4be194fdd86bc40b7c7d instead\n",
      "Created version '7' of model 'nyc-taxi-model'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Registra este mejor modelo en el mismo Registered Model y asígnale alias \"challenger\"\n",
    "model_uri = f\"runs:/{best_run_id}/model\"\n",
    "result = mlflow.register_model(model_uri=model_uri, name=REGISTERED_MODEL_NAME)\n",
    "\n",
    "# Espera a que se materialice la versión (en sqlite suele ser inmediato)\n",
    "time.sleep(2)\n",
    "\n",
    "# Obtén la última versión (la que acabamos de crear)\n",
    "versions = client.search_model_versions(f\"name = '{REGISTERED_MODEL_NAME}'\")\n",
    "latest_version = max(int(v.version) for v in versions)\n",
    "client.set_registered_model_alias(name=REGISTERED_MODEL_NAME, alias=\"challenger\", version=latest_version)\n",
    "\n",
    "latest_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8639260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/msgarcia/Desktop/School/proyecto_2/nyc-taxi-predictions-2025/.venv/lib/python3.11/site-packages/mlflow/data/dataset_source_registry.py:148: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../data/green_tripdata_2024-03.parquet'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "/Users/msgarcia/Desktop/School/proyecto_2/nyc-taxi-predictions-2025/.venv/lib/python3.11/site-packages/mlflow/data/dataset_source_registry.py:148: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "/Users/msgarcia/Desktop/School/proyecto_2/nyc-taxi-predictions-2025/.venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_path = \"../data/green_tripdata_2024-03.parquet\"\n",
    "df_test = read_dataframe(test_path)\n",
    "\n",
    "# Log as artifact + como input dataset dentro de un run \"dataset-log\"\n",
    "with mlflow.start_run(run_name=\"log_2024-03_dataset\"):\n",
    "    # artifact\n",
    "    mlflow.log_artifact(test_path, artifact_path=\"datasets\")\n",
    "\n",
    "    # input dataset (si tu versión de MLflow lo soporta)\n",
    "    try:\n",
    "        ds = mlflow.data.from_pandas(df_test, source=test_path, name=\"green_tripdata_2024-03\")\n",
    "        mlflow.log_input(ds, context=\"testing\")\n",
    "    except Exception as e:\n",
    "        print(\"log_input no disponible / opcional:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e004dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[champion] No se encontró preprocessor en artifacts; usando el dv del notebook. Motivo: Failed to download artifacts from path 'preprocessor.b', please ensure that the path is correct.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 2041.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[challenger] No se encontró preprocessor en artifacts; usando el dv del notebook. Motivo: [Errno 2] No such file or directory: 'tmp/challenger/preprocessor/preprocessor.b'\n",
      "Champion RMSE (2024-03):   5.4013 | Latencia: 0.0104 ms/ejemplo\n",
      "Challenger RMSE (2024-03): 5.4334 | Latencia: 0.0017 ms/ejemplo\n",
      "Mejora relativa RMSE: -0.59%\n"
     ]
    }
   ],
   "source": [
    "# Helpers para cargar modelo por alias + su preprocessor\n",
    "def load_model_and_dv_by_alias(name, alias):\n",
    "    mv = client.get_model_version_by_alias(name=name, alias=alias)\n",
    "    # descarga su preprocessor\n",
    "    dst = f\"tmp/{alias}\"\n",
    "    os.makedirs(dst, exist_ok=True)\n",
    "    try:\n",
    "        client.download_artifacts(run_id=mv.run_id, path=\"preprocessor/preprocessor.b\", dst_path=dst)\n",
    "        with open(os.path.join(dst, \"preprocessor\", \"preprocessor.b\"), \"rb\") as f:\n",
    "            dv_local = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[{alias}] No se encontró preprocessor en artifacts; usando el dv del notebook. Motivo:\", e)\n",
    "        dv_local = dv  # fallback (si ambos fueron entrenados con mismo dv)\n",
    "\n",
    "    model = mlflow.pyfunc.load_model(f\"models:/{name}@{alias}\")\n",
    "    return model, dv_local\n",
    "\n",
    "def preprocess_with_dv(df, dv_):\n",
    "    df = df.copy()\n",
    "    df[\"PU_DO\"] = df[\"PULocationID\"] + \"_\" + df[\"DOLocationID\"]\n",
    "    categorical = [\"PU_DO\"]\n",
    "    numerical   = [\"trip_distance\"]\n",
    "    dicts = df[categorical + numerical].to_dict(orient=\"records\")\n",
    "    return dv_.transform(dicts)\n",
    "\n",
    "# Construye X_test con cada dv\n",
    "champion_model, champion_dv = load_model_and_dv_by_alias(REGISTERED_MODEL_NAME, \"champion\")\n",
    "challenger_model, challenger_dv = load_model_and_dv_by_alias(REGISTERED_MODEL_NAME, \"challenger\")\n",
    "\n",
    "X_test_champion = preprocess_with_dv(df_test, champion_dv)\n",
    "X_test_challenger = preprocess_with_dv(df_test, challenger_dv)\n",
    "y_test = df_test[\"duration\"].values\n",
    "\n",
    "# Predicción y métricas\n",
    "def timed_predict(model, X):\n",
    "    tic = time.time()\n",
    "    y_pred = model.predict(X)\n",
    "    latency = (time.time() - tic) / len(y_pred)  # s/ejemplo\n",
    "    return y_pred, latency\n",
    "\n",
    "y_pred_ch, lat_ch = timed_predict(champion_model, X_test_champion)\n",
    "y_pred_cl, lat_cl = timed_predict(challenger_model, X_test_challenger)\n",
    "\n",
    "rmse_champion   = root_mean_squared_error(y_test, y_pred_ch)\n",
    "rmse_challenger = root_mean_squared_error(y_test, y_pred_cl)\n",
    "\n",
    "print(f\"Champion RMSE (2024-03):   {rmse_champion:.4f} | Latencia: {lat_ch*1000:.4f} ms/ejemplo\")\n",
    "print(f\"Challenger RMSE (2024-03): {rmse_challenger:.4f} | Latencia: {lat_cl*1000:.4f} ms/ejemplo\")\n",
    "print(f\"Mejora relativa RMSE: {(rmse_champion - rmse_challenger)/rmse_champion*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8745c323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejora relativa: -0.59% | Ratio latencia challenger/champion: 0.17\n",
      "¿Promover a champion?: NO ❌\n"
     ]
    }
   ],
   "source": [
    "# Criterios ejemplo (ajústalos a tu contexto):\n",
    "# 1) Mejora de RMSE >= 3%\n",
    "# 2) Latencia no empeora > 20% (por ejemplo en producción)\n",
    "# 3) Complejidad razonable (para árboles, número de estimadores <= 600, etc.)\n",
    "\n",
    "improvement = (rmse_champion - rmse_challenger) / rmse_champion\n",
    "latency_ratio = lat_cl / lat_ch\n",
    "\n",
    "promote = (improvement >= 0.06) and (latency_ratio <= 1.2)\n",
    "\n",
    "print(f\"Mejora relativa: {improvement*100:.2f}% | Ratio latencia challenger/champion: {latency_ratio:.2f}\")\n",
    "print(\"¿Promover a champion?:\", \"SÍ ✅\" if promote else \"NO ❌\")\n",
    "\n",
    "# Si decides promover:\n",
    "if promote:\n",
    "    mv = client.get_model_version_by_alias(name=REGISTERED_MODEL_NAME, alias=\"challenger\")\n",
    "    client.set_registered_model_alias(name=REGISTERED_MODEL_NAME, alias=\"champion\", version=mv.version)\n",
    "    print(f\"Promovido: challenger v{mv.version} ahora es 'champion'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833644f4",
   "metadata": {},
   "source": [
    "En los experimentos realizados con Gradient Boosting y Random Forest como modelos candidatos (challengers), el mejor modelo obtuvo un RMSE 0.59 % mayor que el modelo actualmente desplegado (champion).\n",
    "Aunque presenta menor latencia de inferencia (~83 % más rápido), la pérdida de precisión es prioritaria en este caso.\n",
    "Por tanto, no se promueve el modelo challenger a champion. Se mantendrá el modelo vigente y se realizarán nuevos experimentos ajustando los hiperparámetros del challenger para mejorar el trade-off entre precisión y velocidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c79fb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc-taxi-predictions-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
